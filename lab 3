import tensorflow as tf
tf.enable_eager_execution()
import numpy as np
# numpy를 나타냄.

X = np.array([1, 2, 3])
Y = np.array([1, 2, 3])
# X,y입력, 출력을 1,2,3으로 동일함.


def cost_func(W, X, Y):
  hypothesis = X * w
return tf.reduce_mean(tf.square(hypothesis - Y))
# hypothesis는 x*w. hypothesis에 y를 뺌. 그리고 제곱하여 평균을 내는 코스트 함수 공식을 그대로 입력한 거임. 


W_values = np.linspace(-3, 5, num=15)
cost_values = []
# feed_w는 -3~5의 15개 구간 값을 가짐. 
# feed_w값에 의해 cost가 얼마가 나오는지 출력. 


for feed_W in W_values:
    curr_cost = cost_func(feed_W, X, Y)
    cost_values.append(curr_cost)
    print("{:6.3f} | {:10.5f}".format(feed_W, curr_cost))
# feed_w값을 뽑아 cost함수가 feed_w값에 따라서 어떻게 변화해가는지 출력. 


-3.000 |   74.66667
-2.429 |   54.85714
-1.857 |   38.09524
-1.286 |   24.38095
-0.714 |   13.71429
-0.143 |    6.09524
 0.429 |    1.52381
 1.000 |    0.00000
 1.571 |    1.52381
 2.143 |    6.09524
 2.714 |   13.71429
 3.286 |   24.38095
 3.857 |   38.09524
 4.429 |   54.85714
 5.000 |   74.66667

# 결과값: w값은 -3~5까지 바뀜. cost는 w 값에 따라 점점 줄다가 w가 1일 때 최소가 되고 다시 늘어남.




tf.set_random_seed(0)  # for reproducibility 
# random_seed 초기화.(다음에 실행했을 때에도 같은게 될 수 있게 특정한 값으로 초기화.)

x_data = [1., 2., 3., 4.]
y_data = [1., 3., 5., 7.]
# x, y데이터를 준비.

W = tf.Variable(tf.random_normal([1], -100., 100.))
# variable로 w를 정의. 정규 분포를 따르는 랜덤 넘버를 1개짜리로 변수를 만들어서 w에 정의 합니다.  

for step in range(300):
    hypothesis = W * X
    cost = tf.reduce_mean(tf.square(hypothesis - Y))
# gradient decent부분을 300회 실행. 
Hypothesis와 cost함수를 정의. 

#-cost함수를 미분한 코드-
    alpha = 0.01
    gradient = tf.reduce_mean(tf.multiply(tf.multiply(W, X) - Y, X))
# w(x)-y에 x를 곱. 이 값의 평균을 구한게 gradient.

    descent = W - tf.multiply(alpha, gradient)
# gradient에 alpha를 곱하고 w에서 뺌. W.assign(descent)
# 새로운 w값을 w에 적용함으로써 업데이트.

    
    if step % 10 == 0:
        print('{:5} | {:10.4f} | {:10.6f}'.format(
            step, cost.numpy(), W.numpy()[0]))
# 10번에 한번 씩 cost값과 w값을 출력.

0 | 11716.3086 | 48.767971 
10 | 4504.9126 | 30.619968 
20 | 1732.1364 | 19.366755 
30 | 666.0052 | 12.388859 
40 | 256.0785 | 8.062004 
50 | 98.4620 | 5.379007 
60 | 37.8586 | 3.715335 
70 | 14.5566 | 2.683725 
80 | 5.5970 | 2.044044 
90 | 2.1520 | 1.647391 
100 | 0.8275 | 1.401434 
110 | 0.3182 | 1.248922 
120 | 0.1223 | 1.154351 
130 | 0.0470 | 1.095710 
140 | 0.0181 | 1.059348 
150 | 0.0070 | 1.036801 
160 | 0.0027 | 1.022819 
170 | 0.0010 | 1.014150 
180 | 0.0004 | 1.008774 
190 | 0.0002 | 1.005441 
200 | 0.0001 | 1.003374 
210 | 0.0000 | 1.002092
220 | 0.0000 | 1.001297 
230 | 0.0000 | 1.000804 
240 | 0.0000 | 1.000499 
250 | 0.0000 | 1.000309 
260 | 0.0000 | 1.000192 
270 | 0.0000 | 1.000119 
280 | 0.0000 | 1.000074 
290 | 0.0000 | 1.000046

결과값: cost는 큰 값을 가지고 있다가 0으로 수렴해감. w 값은 랜덤 값이 였다가 특정 값으로 수렴.

EX) W = tf.Variable([5.0])
# 예를 들어서 w에 어떤 특정한 값을 주어도 결과 값은 동일하게 나타납니다. 


0 |    74.6667 |   4.813334
   10 |    28.7093 |   3.364572
   20 |    11.0387 |   2.466224
   30 |     4.2444 |   1.909177
   40 |     1.6320 |   1.563762
   50 |     0.6275 |   1.349578
   60 |     0.2413 |   1.216766
   70 |     0.0928 |   1.134412
   80 |     0.0357 |   1.083346
   90 |     0.0137 |   1.051681
  100 |     0.0053 |   1.032047
  110 |     0.0020 |   1.019871
  120 |     0.0008 |   1.012322
  130 |     0.0003 |   1.007641
  140 |     0.0001 |   1.004738
  150 |     0.0000 |   1.002938
  160 |     0.0000 |   1.001822
  170 |     0.0000 |   1.001130
  180 |     0.0000 |   1.000700
  190 |     0.0000 |   1.000434
  200 |     0.0000 |   1.000269
  210 |     0.0000 |   1.000167
  220 |     0.0000 |   1.000103
  230 |     0.0000 |   1.000064
  240 |     0.0000 |   1.000040
  250 |     0.0000 |   1.000025
  260 |     0.0000 |   1.000015
  270 |     0.0000 |   1.000009
  280 |     0.0000 |   1.000006
  290 |     0.0000 |   1.000004
결과값: cost값은 어떤 큰 숫자에서 0으로 수렴. w값은 특정한 값으로 수렴. 위의 결과와 동일.  


